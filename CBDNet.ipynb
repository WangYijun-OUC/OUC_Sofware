{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/OUCTheoryGroup/colab_demo/blob/master/202003_models/CBDNet_CVPR2019.ipynb","timestamp":1668691440729}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os, time, scipy.io, shutil\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import glob\n","import re\n","import cv2\n","\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","path = \"/content/drive/My Drive\"\n","\n","os.chdir(path)\n","os.listdir(path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WV0cnJmkLXYJ","executionInfo":{"status":"ok","timestamp":1669791668999,"user_tz":-480,"elapsed":26159,"user":{"displayName":"王义钧","userId":"08631799108825331241"}},"outputId":"f4f6646f-9ed9-450d-a71c-b5179d554f5a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["['imagenet_class_index.json',\n"," 'dogscats.zip.1',\n"," 'Colab Notebooks',\n"," '0503.ipynb',\n"," 'Untitled',\n"," '0502.ipynb',\n"," 'dogscats',\n"," 'model_best_new.pth',\n"," 'yanxishe',\n"," 'cat_dog',\n"," 'result.csv',\n"," 'Dog_vs_Cat.ipynb',\n"," 'mini_denoise_dataset.zip',\n"," 'mini_denoise_dataset',\n"," 'result',\n"," 'CBDNet.py',\n"," '__pycache__',\n"," 'CBDNet_model.pth',\n"," 'CBDNet_model_dict.pth',\n"," 'Test.ipynb',\n"," 'CBDNet.ipynb']"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"QO5OkcnczqzJ"},"source":["CBDNet类定义："]},{"cell_type":"code","metadata":{"id":"EZ4YdqzZ_hMQ","executionInfo":{"status":"ok","timestamp":1669791672571,"user_tz":-480,"elapsed":3,"user":{"displayName":"王义钧","userId":"08631799108825331241"}}},"source":["class FCN(nn.Module):\n","    def __init__(self):\n","        super(FCN, self).__init__()\n","\n","        # 3 ==> 32 的输入卷积\n","        self.inc = nn.Sequential(\n","            nn.Conv2d(3, 32, 3, padding=1),\n","            nn.ReLU(inplace=True))\n","        \n","        # 32 ==> 32 的中间卷积\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(32, 32, 3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","        \n","        # 32 ==> 3 的输出卷积 \n","        self.outc = nn.Sequential(\n","            nn.Conv2d(32, 3, 3, padding=1),\n","            nn.ReLU(inplace=True)\n","        )\n","    \n","    def forward(self, x):\n","        # 第 1 次卷积\n","        conv1 = self.inc(x)\n","        # 第 2 次卷积\n","        conv2 = self.conv(conv1)\n","        # 第 3 次卷积\n","        conv3 = self.conv(conv2)\n","        # 第 4 次卷积\n","        conv4 = self.conv(conv3)\n","        # 第 5 次卷积\n","        conv5 = self.outc(conv4)\n","        return conv5\n","\n","class single_conv(nn.Module):\n","    def __init__(self, in_ch, out_ch):\n","        super(single_conv, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n","            nn.ReLU(inplace=True))\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x\n","\n","class up(nn.Module):\n","    def __init__(self, in_ch):\n","        super(up, self).__init__()\n","        self.up = nn.ConvTranspose2d(in_ch, in_ch//2, 2, stride=2)\n","\n","    # forward 需要两个输入，x1 是需要上采样的小尺寸 feature map\n","    # x2 是以前的大尺寸 feature map，因为中间的 pooling 可能损失了边缘像素，\n","    # 所以上采样以后的 x1 可能会比 x2 尺寸小\n","    def forward(self, x1, x2):\n","        # x1 上采样\n","        x1 = self.up(x1)\n","        \n","        # 输入数据是四维的，第一个维度是样本数，剩下的三个维度是 CHW\n","        # 所以 Y 方向上的悄寸差别在 [2],  X 方向上的尺寸差别在 [3] \n","        diffY = x2.size()[2] - x1.size()[2]\n","        diffX = x2.size()[3] - x1.size()[3]\n","        # 给 x1 进行 padding 操作\n","        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n","                        diffY // 2, diffY - diffY//2))\n","        # 把 x2 加到反卷积后的 feature map\n","        x = x2 + x1\n","        return x\n","\n","class outconv(nn.Module):\n","    def __init__(self, in_ch, out_ch):\n","        super(outconv, self).__init__()\n","        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x\n","\n","class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","\n","        self.inc = nn.Sequential(\n","            single_conv(6, 64),\n","            single_conv(64, 64))\n","\n","        self.down1 = nn.AvgPool2d(2)\n","        self.conv1 = nn.Sequential(\n","            single_conv(64, 128),\n","            single_conv(128, 128),\n","            single_conv(128, 128))\n","\n","        self.down2 = nn.AvgPool2d(2)\n","        self.conv2 = nn.Sequential(\n","            single_conv(128, 256),\n","            single_conv(256, 256),\n","            single_conv(256, 256),\n","            single_conv(256, 256),\n","            single_conv(256, 256),\n","            single_conv(256, 256))\n","\n","        self.up1 = up(256)\n","        self.conv3 = nn.Sequential(\n","            single_conv(128, 128),\n","            single_conv(128, 128),\n","            single_conv(128, 128))\n","\n","        self.up2 = up(128)\n","        self.conv4 = nn.Sequential(\n","            single_conv(64, 64),\n","            single_conv(64, 64))\n","\n","        self.outc = outconv(64, 3)\n","\n","    def forward(self, x):\n","        # input conv : 6 ==> 64 ==> 64\n","        inx = self.inc(x)\n","\n","        # 均值 pooling, 然后 conv1 : 64 ==> 128 ==> 128 ==> 128\n","        down1 = self.down1(inx)\n","        conv1 = self.conv1(down1)\n","\n","        # 均值 pooling，然后 conv2 : 128 ==> 256 ==> 256 ==> 256 ==> 256 ==> 256 ==> 256\n","        down2 = self.down2(conv1)\n","        conv2 = self.conv2(down2)\n","\n","        # up1 : conv2 反卷积，和 conv1 的结果相加，输入256，输出128\n","        up1 = self.up1(conv2, conv1)\n","        # conv3 : 128 ==> 128 ==> 128 ==> 128\n","        conv3 = self.conv3(up1)\n","\n","        # up2 : conv3 反卷积，和 input conv 的结果相加，输入128，输出64\n","        up2 = self.up2(conv3, inx)\n","        # conv4 : 64 ==> 64 ==> 64\n","        conv4 = self.conv4(up2)\n","\n","        # output conv: 65 ==> 3，用1x1的卷积降维，得到降噪结果\n","        out = self.outc(conv4)\n","        return out\n","\n","class CBDNet(nn.Module):\n","    def __init__(self):\n","        super(CBDNet, self).__init__()\n","        self.fcn = FCN()\n","        self.unet = UNet()\n","    \n","    def forward(self, x):\n","        noise_level = self.fcn(x)\n","        concat_img = torch.cat([x, noise_level], dim=1)\n","        out = self.unet(concat_img) + x\n","        return noise_level, out"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ef45SuXPY2Q-"},"source":["### 2.4 损失函数设计\n","\n","损失函数包括三部分：\n","\n","![损失函数说明](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200303132845.jpg)\n","\n","三个部分加在一起，就是最终的损失函数，下面结合代码来看。"]},{"cell_type":"code","metadata":{"id":"YV21RySPdw8Q","executionInfo":{"status":"ok","timestamp":1669791681821,"user_tz":-480,"elapsed":593,"user":{"displayName":"王义钧","userId":"08631799108825331241"}}},"source":["class fixed_loss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        \n","    def forward(self, out_image, gt_image, est_noise, gt_noise, if_asym):\n","        # 分别得到图像的高度和宽度\n","        h_x = est_noise.size()[2]\n","        w_x = est_noise.size()[3]\n","        # 每个样本为 CHW ，把 H 方向第一行的数据去掉，统计一下一共多少元素\n","        count_h = self._tensor_size(est_noise[:, :, 1:, :])\n","        # 每个样本为 CHW ，把 W 方向第一列的数据去掉，统计一下一共多少元素\n","        count_w = self._tensor_size(est_noise[:, :, : ,1:])\n","        # H 方向，第一行去掉得后的矩阵，减去最后一行去掉后的矩阵，即下方像素减去上方像素，平方，然后求和\n","        h_tv = torch.pow((est_noise[:, :, 1:, :] - est_noise[:, :, :h_x-1, :]), 2).sum()\n","        # W 方向，第一列去掉得后的矩阵，减去最后一列去掉后的矩阵，即右方像素减去左方像素，平方，然后求和\n","        w_tv = torch.pow((est_noise[:, :, :, 1:] - est_noise[:, :, :, :w_x-1]), 2).sum()\n","        # 求平均，得到平均每个像素上的 tvloss\n","        tvloss = h_tv / count_h + w_tv / count_w\n","\n","        loss = torch.mean( \\\n","                # 第三部分：重建损失\n","                torch.pow((out_image - gt_image), 2)) + \\\n","                if_asym * 0.5 * torch.mean(torch.mul(torch.abs(0.3 - F.relu(gt_noise - est_noise)), torch.pow(est_noise - gt_noise, 2))) + \\\n","                0.05 * tvloss\n","        return loss\n","\n","    def _tensor_size(self,t):\n","        return t.size()[1]*t.size()[2]*t.size()[3]\n","\n","# 这个类用于存储 loss，观察结果时使用\n","# 每轮训练一张图像，就计算一下 loss 的均值存储在 self.avg 里，用于输出观察变化\n","# 同时，把当前 loss 的值存储在 self.val 里\n","class AverageMeter(object):\n","\tdef __init__(self):\n","\t\tself.reset()\n","\n","\tdef reset(self):\n","\t\tself.val = 0\n","\t\tself.avg = 0\n","\t\tself.sum = 0\n","\t\tself.count = 0\n","\n","\tdef update(self, val, n=1):\n","\t\tself.val = val\n","\t\tself.sum += val * n\n","\t\tself.count += n\n","\t\tself.avg = self.sum / self.count\n","\n","# 图像矩阵由 hwc 转换为 chw ，这个就不多解释了\n","def hwc_to_chw(img):\n","    return np.transpose(img, axes=[2, 0, 1])\n","# 图像矩阵由 chw 转换为 hwc ，这个也不多解释\n","def chw_to_hwc(img):\n","    return np.transpose(img, axes=[1, 2, 0])"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vjMhEpNLz5kL"},"source":["从上面的代码中可以看到，对比损失前系数为 0.5， alpha 取值为 0.3，tvloss 系数为 0.05，和论文里的默认参数一致。\n","\n","**【划重点】这里需要专门指出的是：**\n","\n","对于 gt_noise，只有在使用合成数据进行训练时才会用到；以前的图像去噪，大多在真实图像上加一个随机Gauss噪声，得到噪声图像，这时 gt_noise 是已知的，就能够输入。\n","\n","这个教程里处理的是真实图像，因此没有 gt_noise，所以在训练时，gt_noise 一直是0。原来代码里专门有一部分是人工合成噪声来训练，为方便理解代码，我暂时去掉了这部分。\n","\n","\n","下面是两个程序中要用到的两个小函数："]},{"cell_type":"code","metadata":{"id":"nHW4KXRqsYfD","executionInfo":{"status":"ok","timestamp":1669791682430,"user_tz":-480,"elapsed":2,"user":{"displayName":"王义钧","userId":"08631799108825331241"}}},"source":["# 这个类用于存储 loss，观察结果时使用\n","# 每轮训练一张图像，就计算一下 loss 的均值存储在 self.avg 里，用于输出观察变化\n","# 同时，把当前 loss 的值存储在 self.val 里\n","class AverageMeter(object):\n","\tdef __init__(self):\n","\t\tself.reset()\n","\n","\tdef reset(self):\n","\t\tself.val = 0\n","\t\tself.avg = 0\n","\t\tself.sum = 0\n","\t\tself.count = 0\n","\n","\tdef update(self, val, n=1):\n","\t\tself.val = val\n","\t\tself.sum += val * n\n","\t\tself.count += n\n","\t\tself.avg = self.sum / self.count\n","\n","# 图像矩阵由 hwc 转换为 chw ，这个就不多解释了\n","def hwc_to_chw(img):\n","    return np.transpose(img, axes=[2, 0, 1])\n","# 图像矩阵由 chw 转换为 hwc ，这个也不多解释\n","def chw_to_hwc(img):\n","    return np.transpose(img, axes=[1, 2, 0])"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eNv0v8q_1DpR"},"source":["## 3. 初始化基本变量，开始训练"]},{"cell_type":"code","metadata":{"id":"QOx6E7pQzoAl","executionInfo":{"status":"ok","timestamp":1669791949318,"user_tz":-480,"elapsed":615,"user":{"displayName":"王义钧","userId":"08631799108825331241"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ca6f8e8-a860-43c6-fe56-1e041481838a"},"source":["test_dir = './mini_denoise_dataset/test/'\n","test_fns = glob.glob(test_dir + '*.bmp' and test_dir + '*.JPG')\n","print(test_fns)\n","# 建立 result 目录，保存图片处理结果\n","result_dir = './mini_denoise_dataset/result/'\n","if not os.path.exists( result_dir ):\n","    os.mkdir( result_dir )\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["['./mini_denoise_dataset/test/0011.JPG']\n"]}]},{"cell_type":"markdown","metadata":{"id":"08AZTF6u4Rc2"},"source":["开始测试："]},{"cell_type":"code","metadata":{"id":"5_oa6jN84Q25","executionInfo":{"status":"ok","timestamp":1669791955330,"user_tz":-480,"elapsed":2842,"user":{"displayName":"王义钧","userId":"08631799108825331241"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"05b139bf-8d3b-47c2-86cd-7d1fee2c7b6e"},"source":["for ind, test_img_path in enumerate(test_fns):\n","    the_model = torch.load('/content/drive/My Drive/CBDNet_model.pth')\n","    the_model.eval()\n","    with torch.no_grad():\n","        print(test_img_path)\n","        # 读入图像，切换RGB通道并归一化，转化为 numpy float32格式\n","        noisy_img = cv2.imread(test_img_path)\n","        noisy_img = noisy_img[:,:,::-1] / 255.0\n","        noisy_img = np.array(noisy_img).astype('float32')\n","\n","        # 转化为 chw 才符合 pytorch 网络的输入格式\n","        temp_noisy_img_chw = hwc_to_chw(noisy_img)\n","        # 图像放到 gpu 上\n","        input_var = torch.from_numpy(temp_noisy_img_chw.copy()).type(torch.FloatTensor).unsqueeze(0).to(device)\n","        # 输入模型得到结果\n","        _, output = the_model(input_var)\n","\n","        # 输出结果转化为 numpy ，同时，把数据转到 0，1 之间（因为可能会有一些异常值）\n","        output_np = output.squeeze().cpu().detach().numpy()\n","        output_np = chw_to_hwc(np.clip(output_np, 0, 1))\n","        # 把噪声图像，和降噪后的图像拼接在一起，然后保存图像\n","        tempImg = np.concatenate((noisy_img, output_np), axis=1)*255.0\n","        \n","        Image.fromarray(np.uint8(tempImg)).save(fp=result_dir + 'test_%d.jpg'%(ind), format='JPEG')"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["./mini_denoise_dataset/test/0011.JPG\n"]}]},{"cell_type":"markdown","metadata":{"id":"ElnAIC2CZouE"},"source":["代码运行结束，下面是10张测试图片的效果：\n","\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212300.jpg)\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212301.jpg)\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212302.jpg)\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212303.jpg)\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212304.jpg)\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212305.jpg)\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212306.jpg)\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212307.jpg)\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212308.jpg)\n","\n","![替代文字](https://gaopursuit.oss-cn-beijing.aliyuncs.com/202003/20200302212309.jpg)\n","\n","\n","可以看到，去噪的效果有了，但是感觉有些模糊。也许是训练数据用的不够，也许是训练的 epoch 还不够多 ~~~ 有机会会在本地服务器，用更多的训练数据实验一下。"]}]}